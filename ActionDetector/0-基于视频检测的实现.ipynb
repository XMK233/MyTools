{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dc694e-5e94-406e-ac0a-3ff1143df8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from slowfast.config.defaults import get_cfg\n",
    "from slowfast.models import build_model\n",
    "from slowfast.utils import checkpoint as cu\n",
    "from slowfast.utils.parser import load_config_file\n",
    "import time\n",
    "from threading import Thread, Event\n",
    "\n",
    "class ArcheryActionDetector:\n",
    "    def __init__(self, config_file=\"slowfast/configs/Kinetics/SLOWFAST_8x8_R50.yaml\"):\n",
    "        # åˆå§‹åŒ–SlowFastæ¨¡å‹\n",
    "        self.cfg = get_cfg()\n",
    "        load_config_file(self.cfg, config_file)\n",
    "        self.cfg.NUM_GPUS = 0  # ä½¿ç”¨CPUæ¨ç†\n",
    "        self.model = build_model(self.cfg)\n",
    "        cu.load_checkpoint(\"path/to/checkpoint.pyth\", self.model)\n",
    "        self.model.eval()\n",
    "\n",
    "        # è§†é¢‘æµå‚æ•°\n",
    "        self.clip_length = 32  # æ¨¡å‹è¾“å…¥å¸§æ•°\n",
    "        self.cap_interval = 0.5  # æ£€æµ‹é—´éš”ï¼ˆç§’ï¼‰\n",
    "        self.buffer = []\n",
    "        self.last_action_time = 0\n",
    "        self.action_count = 0\n",
    "        self.is_action_ongoing = False\n",
    "        self.action_start_time = 0\n",
    "\n",
    "        # åˆå§‹åŒ–æ‘„åƒå¤´\n",
    "        self.cap = cv2.VideoCapture(0)\n",
    "        self.stop_event = Event()\n",
    "\n",
    "    def preprocess_frame(self, frame):\n",
    "        \"\"\"é¢„å¤„ç†å•å¸§å›¾åƒ\"\"\"\n",
    "        frame = cv2.resize(frame, (256, 256))\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        return frame / 255.0\n",
    "\n",
    "    def process_clip(self):\n",
    "        \"\"\"å¤„ç†è§†é¢‘ç‰‡æ®µå¹¶è¿›è¡Œæ¨ç†\"\"\"\n",
    "        if len(self.buffer) < self.clip_length:\n",
    "            return\n",
    "\n",
    "        # è½¬æ¢ä¸ºæ¨¡å‹è¾“å…¥æ ¼å¼\n",
    "        inputs = [torch.from_numpy(np.array(self.buffer)).float()]\n",
    "        inputs = [i.permute(3, 0, 1, 2) for i in inputs]  # CTHW\n",
    "\n",
    "        # æ‰§è¡Œæ¨ç†\n",
    "        with torch.no_grad():\n",
    "            preds = self.model(inputs)\n",
    "        \n",
    "        # è§£æé¢„æµ‹ç»“æœ\n",
    "        action_prob = torch.softmax(preds[0], dim=0)[1].item()\n",
    "        return action_prob\n",
    "\n",
    "    def camera_worker(self):\n",
    "        \"\"\"æ‘„åƒå¤´é‡‡é›†çº¿ç¨‹\"\"\"\n",
    "        while not self.stop_event.is_set():\n",
    "            ret, frame = self.cap.read()\n",
    "            if ret:\n",
    "                processed = self.preprocess_frame(frame)\n",
    "                self.buffer.append(processed)\n",
    "                # ä¿æŒç¼“å†²åŒºé•¿åº¦\n",
    "                if len(self.buffer) > self.clip_length * 2:\n",
    "                    self.buffer = self.buffer[-self.clip_length:]\n",
    "                \n",
    "            time.sleep(0.01)\n",
    "\n",
    "    def detection_worker(self):\n",
    "        \"\"\"åŠ¨ä½œæ£€æµ‹çº¿ç¨‹\"\"\"\n",
    "        while not self.stop_event.is_set():\n",
    "            current_time = time.time()\n",
    "            if current_time - self.last_action_time >= self.cap_interval:\n",
    "                if len(self.buffer) >= self.clip_length:\n",
    "                    prob = self.process_clip()\n",
    "                    self.update_action_state(prob, current_time)\n",
    "                self.last_action_time = current_time\n",
    "            time.sleep(0.01)\n",
    "\n",
    "    def update_action_state(self, prob, current_time):\n",
    "        \"\"\"æ›´æ–°åŠ¨ä½œçŠ¶æ€æœº\"\"\"\n",
    "        threshold = 0.85  # åˆ†ç±»é˜ˆå€¼\n",
    "        min_duration = 1.0  # æœ€å°æœ‰æ•ˆåŠ¨ä½œæŒç»­æ—¶é—´ï¼ˆç§’ï¼‰\n",
    "\n",
    "        if not self.is_action_ongoing and prob > threshold:\n",
    "            # æ£€æµ‹åˆ°åŠ¨ä½œå¼€å§‹\n",
    "            self.is_action_ongoing = True\n",
    "            self.action_start_time = current_time\n",
    "            print(f\"ğŸ¹ æ‹‰å¼“åŠ¨ä½œå¼€å§‹ @ {time.strftime('%H:%M:%S')}\")\n",
    "\n",
    "        elif self.is_action_ongoing:\n",
    "            if prob < threshold:\n",
    "                # åŠ¨ä½œç»“æŸ\n",
    "                duration = current_time - self.action_start_time\n",
    "                if duration >= min_duration:\n",
    "                    self.action_count += 1\n",
    "                    print(f\"âœ… å®Œæˆæ‹‰å¼“åŠ¨ä½œï¼æŒç»­æ—¶é—´ï¼š{duration:.2f}s æ€»è®¡ï¼š{self.action_count}æ¬¡\")\n",
    "                else:\n",
    "                    print(\"âš ï¸ æ£€æµ‹åˆ°çŸ­æ—¶åŠ¨ä½œï¼ˆå¿½ç•¥è®¡æ•°ï¼‰\")\n",
    "                self.is_action_ongoing = False\n",
    "            else:\n",
    "                # æ›´æ–°æŒç»­æ—¶é—´æ˜¾ç¤º\n",
    "                duration = current_time - self.action_start_time\n",
    "                print(f\"â± æŒç»­æ‹‰å¼“ä¸­... {duration:.1f}s\", end='\\r')\n",
    "\n",
    "    def start(self):\n",
    "        Thread(target=self.camera_worker, daemon=True).start()\n",
    "        Thread(target=self.detection_worker, daemon=True).start()\n",
    "        print(\"ç³»ç»Ÿå·²å¯åŠ¨ï¼Œå¼€å§‹æ£€æµ‹æ‹‰å¼“åŠ¨ä½œ...\")\n",
    "\n",
    "    def stop(self):\n",
    "        self.stop_event.set()\n",
    "        self.cap.release()\n",
    "        print(\"\\nç³»ç»Ÿå·²åœæ­¢\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    detector = ArcheryActionDetector()\n",
    "    detector.start()\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            time.sleep(1)\n",
    "    except KeyboardInterrupt:\n",
    "        detector.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
